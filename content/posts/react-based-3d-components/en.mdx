---
title: 'React-based 3D Components'
author: 'onichandame'
date: 2020-05-13
---

<!-- vim-markdown-toc GFM -->

- [Background](#background)
- [Demand Analysis](#demand-analysis)
  - [End-User Experience](#end-user-experience)
  - [Technical Constraints](#technical-constraints)
- [Technology Analysis](#technology-analysis)
  - [React 360](#react-360)
  - [Babylon](#babylon)
  - [Three-based Solution](#three-based-solution)
    - [React-Three-Fiber](#react-three-fiber)
- [Implementation](#implementation)
  - [Design](#design)
  - [Model Loading](#model-loading)
  - [Viewport Movement](#viewport-movement)

<!-- vim-markdown-toc -->

This is a record of my personal experience on the 3D React component development. The content may be updated at any time because the project is still under development.

# Background

I need to design and build a 3D based building information modelling(BIM). This BIM component needs to reside in an existing system based on Next.js, a UI framework based on React and specialized in SSR optimization.

# Demand Analysis

## End-User Experience

The end user is an untrained worker who is not specialzed in either IT or BIM. Therefore the functions are simple and understandable for every computer user.

1. An intrinsic mapping between the UI and the real building, down to the component level
2. An intrinsic interactive pattern based on ray casting
3. All texts and numbers on the UI must be clear and minimal
4. A camera reset button, a scene reload button and a virtual button on each component to enter the corresponding page of details

## Technical Constraints

1. Must be integrated into a Next.js project
2. Must be able to load 3D models like GLTF and OBJ
3. Must be code-splitted to minimize the impact on the performance of the original website

# Technology Analysis

Based on the demand analysis, I conducted research to find some existing technologies that I can make use of. Many good frameworks are found but they all boils down to 3 fundamental technologies.

## React 360

This is a framework built by Facebook for VR development. It also supports 3D UI out of the box. By default it loads models from GLTF and OBJ formats. At the first glance it may be the best choice for the following reasons:

1. 3D out of the box
2. interactive out of the box
3. supports open source models GLTF and OBJ

But it is based on React Native, which makes it difficult to integrate into the existing webpage. Truly it can be embedded in `<iframe>`. But this workaround brings more complexities into the deployment phase. Moreover, this framework aims at VR, which is not a 100% overlap with BIM. Not to say that this framework is not as popular as its competitors, which means that it is more defficult to get help from the community.

## Babylon

This framework supports the integration with React officially, according to the [official docs](https://doc.babylonjs.com/resources/babylonjs_and_reactjs). However the docs also mentions that there may be performance overhead if used with React. The optimal choice is to use the pure JavaScript, which is what I would like to avoid. There are feasible ways such as React DOM or reconciler. But again the community is quite small. [The existing solution](https://github.com/brianzinn/react-babylonjs) has just 140 stars on GitHub at the time of writing this sentence. As an individual developer the size of community is at the top of my list.

## Three-based Solution

Now the main course comes. Three.js is the most popular 3D framework in Web development. It has the largest most active community. However, it is not designed for React hence the React-Three community is not comparable to the entire Three community.

### [React-Three-Fiber][r3f]

This is the most suitable framework in this condition.

1. Deep integration with React with no significant performance overhead
2. Able to load GLTF models using useLoader hook, GLTF loader from Three and React Suspense
3. Just a wrapper around three so info from three community is most likely helpful
4. Many helper packages from the same team that help ray casting, animation and more.

The only hack needed here is the dynamic import of Next.js with SSR disabled. It is not a traditional hack that needs a proper fix, but a non-intuitive but reasonable solution for the problem: 2D rendering is compatible with SSR as SSR produces plain HTML, but 3D requires runtime loading of the resources such as models. If models are wrapped in React components, these components must be dynamically loaded using `next/dynamic`.

Also, dynamic importing of Next.js provides code-splitting out of the box.

# Implementation

This sections records all the major challenges solved during implementation. Basic knowledge of React and 3D development is preassumed.

## Design

As BIM is designed to convey the position and the status of physical components, It should display all the information in one screen for a comprehensive overview of the components. Based on this principle, all components should be layed out in one plane. Thus the camera movement can be constrained to the same plane.

![example](/image/bim-example.jpg)

As shown in the above example, all components are visible in one snapshot. The shape and location are displayed by the model itself and the status is displayed by the color.

The only interactions between BIM and the user are summarized into 2:

1. enter the component's control panel by clicking on the component
2. reset the camera position to initial

The first interaction can be achieved by capturing the "click" event on each component.

The second interaction can be achieved by clicking a reset button in the corner.

## Model Loading

The first problem encountered is to load the models made by the designer. As stated in <a href={'../collaboration-using-blender'}>this post</a>, it is possible to convert models made in SolidWorks to Blender. From Blender, the model can be exported as GLTF files.

[R3F][r3f] provides a hook `useLoader` that can be used in conjunction with `GLTFLoader` from three to dynamically load GLTF files into the model.

```typescript
import { useLoader } from 'react-three-fiber'
import { GLTFLoader } from 'three/examples/jsm/loaders/GLTFLoader'

export const Model = () => {
  const gltf = useLoader(GLTFLoader, '/static/model.gblb')
  return <primitive object={gltf.scene} dispose={null} {...other} />
}
```

## Viewport Movement

There are mainly 2 ways to move the viewport: moving the camera(first-person) or moving the model(god's view). These 2 methods do not differentiate when translating, so the choice is made based on the demanded rotation pattern.

In a big scene where it is impossible to contain all models in one frustrum, the first-person strategy is more intuitive. In a scene where all models can be contained in one frustrum, a god's view is the better choice.

As for BIM, all models should be displayed in one screen so god's view should be adopted.

God's view can be implemented using `useGesture` from `react-use-gesture` and `useSpring` from `@react-spring/core`.

```typescript
import { a } from '@react-spring/three'
const useControl = (
  ...[xBounds, yBounds, zBounds, { domTarget }]: Props
): [
  { x: SpringValue<number>; y: SpringValue<number>; z: SpringValue<number> },
  ReturnType<typeof useGesture>
] => {
  const [{ x }, setX] = useSpring<{ x: number }>(() => ({
    x: 0,
    config: config.slow,
  }))
  const [{ y }, setY] = useSpring<{ y: number }>(() => ({
    y: 5,
    config: config.slow,
  }))
  const [{ z }, setZ] = useSpring<{ z: number }>(() => ({
    z: 5,
    config: config.slow,
  }))
  const zoom = useCallback(
    ({ wheeling, xy: [, newY], previous: [, oldY], memo = z.get() }) => {
      if (wheeling) {
        const newZ = clamp(memo + newY - oldY, ...zBounds)
        setZ({ z: newZ })
        return newZ
      } else {
        return memo
      }
    },
    [zBounds, z, setZ]
  )
  const drag = useCallback(
    ({ dragging, offset: [newX, newY], memo = [x.get(), y.get()] }) => {
      if (dragging) {
        setX({ x: newX })
        setY({ y: -newY })
        return [newX, newY]
      }
      return memo
    },
    [xBounds, yBounds, x, y, setX, setY]
  )
  const bind = useGesture({ onWheel: zoom, onDrag: drag }, { domTarget })
  useEffect(() => {
    domTarget && bind()
  }, [domTarget, bind])
  return [{ x, y, z }, bind]
}

export const App = ({children}) => {
  const bound: [number, number] = [-200, 200]
  const [{ x, y, z }] = useControl(bound, bound, bound, { domTarget: window })
  return (
    <a.group
      position-x={x.interpolate(x => (x / 500) * 10)}
      position-y={y.interpolate(x => (x / 500) * 10)}
      position-z={z.interpolate(x => (x / 500) * 25)}
    >
      {children}
    </a.group>
  )
```

The `App` exported above wraps all the children models in a God's view that can be zoomed and translated.

[r3f]: https://www.npmjs.com/package/react-three-fiber
